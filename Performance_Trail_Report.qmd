---
title: "PFL DATA REPORT"
format: 
  docx:
    reference-doc: 'C:/Users/eric.honert/Boa Technology Inc/PFL Team - General/Testing Segments/Report_Template.docx'
editor: visual
editor_options: 
  chunk_output_type: console
---

(\^Delete)

# CONFIDENTAL CONTENT FOR BOA EMPLOYEES ONLY. PLEASE CONTACT PFL DIRECTLY WITH ANY QUESTIONS.

+--------------------+-----------------------------------+
| Test Name          | EH_Trail_HeelLockTrail_Perf_May23 |
+====================+===================================+
| **Benefit:**       | Endurance & Health                |
+--------------------+-----------------------------------+
| **Date:**          | 5/2023                            |
+--------------------+-----------------------------------+
| **Test Type:**     | Performance                       |
+--------------------+-----------------------------------+
| **Configurations** | Baseline: SD (Single Dial)        |
|                    |                                   |
|                    | Test configurations:              |
|                    |                                   |
|                    | -   SDHL (Single Dial Heel-Lock)  |
|                    |                                   |
|                    | -   DDHL (Dual Dial Heel-Lock)    |
+--------------------+-----------------------------------+

## Purpose & Background

-   Previous cycling performance tests (Cycling_DDRoad_Performance_Feb22) showed improvements due to a heel lock guide providing immediate lace pull toward the heel cut.

-   In-lab testing demonstrated that the single-dial heel lock improved quantitative fit; but neither heel lock configuration improved agility performance

-   The purpose of this test was to evaluate how a heel lock guide affects endurance and health performance in a single dial and dual dial configuration on trail.

## Hypothesis

H1: The heel lock will improve heel hold and the dual dial heel lock will provide the best fit. Heel hold will be measured as contact area between the heel and the midsole during trail running. The heel hold will be evaluated during uphill, technical, and downhill running

H2: The heel lock will improve ankle stability with dual dial heel lock providing the most stability. Ankle stability will be measured as the peak eversion velocity. The

H3: The heel lock will improve running speed with no change in heart rate. The dual dial will provide the most improvement.

## Methods

+------------------+---------------+------------------+----------------------------+
| Subjects         | Movements     | Equipment        | Measurements               |
+==================+===============+==================+============================+
| 10 Male Athletes | Trail Running | Pressure insoles | Endurance:                 |
|                  |               |                  |                            |
|                  |               |                  | -   Running speed          |
|                  |               |                  |                            |
|                  |               |                  | -   Heart Rate             |
|                  |               |                  |                            |
|                  |               |                  | Health:                    |
|                  |               |                  |                            |
|                  |               |                  | -   Peak eversion velocity |
|                  |               |                  |                            |
|                  |               |                  | Fit:                       |
|                  |               |                  |                            |
|                  |               |                  | -   Heel contact area      |
|                  |               |                  |                            |
|                  |               |                  | -   Forefoot pressure      |
+------------------+---------------+------------------+----------------------------+

## Configurations

+-----------------------------+------------------------------+-----------------------------+
| Baseline: Single Dial (SD)  | Single Dial Heel Lock (SDHL) | Dual Dial Heel Lock (DDHL)  |
+=============================+==============================+=============================+
| ![](images/config1_LAT.png) | ![](images/config2_LAT.png)  | ![](images/config3_LAT.png) |
+-----------------------------+------------------------------+-----------------------------+

## Summary of Findings

```{r}
#| echo: false
#| warning: false
#| include: false
library(readxl)
library(tidyverse)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
library(readxl)
library(brms)
library(patchwork)
library(tidyr)
library(fmsb)
library(gt)
rm(list=ls())
```

```{r}
#| echo: false
#| include: false

#Load in Compiled Qualitative Sheet
qualDat <- read_xlsx('C:/Users/eric.honert/Boa Technology Inc/PFL Team - General/Testing Segments/EndurancePerformance/EH_Trail_HeelLockTrail_Perf_May23/Qual_EH_Trail_HeelLockTrail_Perf_May23.xlsx')

# Load in the heart rate data
HRdat <- read.csv('C:/Users/eric.honert/Boa Technology Inc/PFL Team - General/Testing Segments/EndurancePerformance/EH_Trail_HeelLockTrail_Perf_May23/Watch/CombinedGPS.csv')

# Load in the IMU data
IMUdat <- read.csv('C:/Users/eric.honert/Boa Technology Inc/PFL Team - General/Testing Segments/EndurancePerformance/EH_Trail_HeelLockTrail_Perf_May23/IMU/IMUmetrics.csv')

# Load in the insole data
Pressdat <- read.csv('C:/Users/eric.honert/Boa Technology Inc/PFL Team - General/Testing Segments/EndurancePerformance/EH_Trail_HeelLockTrail_Perf_May23/Xsensor/PressureOutcomes.csv')


baseline <- 'SD' # baseline configuration

otherConfigs <- c('SDHL', 'DDHL') # other configurations tested against base
allConfigs <- c(baseline, otherConfigs)


qualDat$Config <- factor(qualDat$Config, allConfigs)


HRdat <- as_tibble(HRdat) # creating the data frame
HRdat$Config <- factor(HRdat$Config, allConfigs)

IMUdat <- as_tibble(IMUdat) # creating the data frame
IMUdat$Config <- factor(IMUdat$Config, allConfigs)

Pressdat <- as_tibble(Pressdat) # creating the data frame
Pressdat$Config <- factor(Pressdat$Config, allConfigs)

withinSubPlot <- function(inputDF, colName, dir) {
  
  # direction can be 'lower' or higher'. It is the direction of change that is better. 
  # For example, for contact time lower is better. so we put 'lower'. for jump height, higher is better, so we put higher. 
  meanDat <- inputDF %>%
    group_by(Subject, Config) %>%
    summarize(mean = mean(!! sym(colName)))
  
  if (dir == 'lower'){
    whichConfig <- meanDat %>%
      group_by(Subject) %>%
      summarize(
        BestConfig = Config[which.min(mean)]
      )
    
  } else if (dir == 'higher') {
    whichConfig <- meanDat %>%
      group_by(Subject) %>% 
      summarize(
        BestConfig = Config[which.max(mean)]
      )
    
  }
  
  whichConfig <- merge(meanDat, whichConfig)
  
  ggplot(data = whichConfig, mapping = aes(x = as.factor(Config), y = mean, col = BestConfig, group = Subject)) + geom_point(size = 4) + 
    geom_line() + xlab('Configuration') + scale_color_manual(values=c("#000000","#00966C", "#ECE81A","#DC582A","#CAF0E4")) + theme(text = element_text(size = 16)) + ylab(paste0({{colName}})) 
  
}


extractVals <- function(dat, mod, configNames, baseConfig, var, dir) {
  
  Config = rep(NA, length(configNames))
  ProbImp = matrix(0, length(configNames))
  lowCI = matrix(0, length(configNames))
  highCI = matrix(0, length(configNames))
  
  for (i in 1:length(configNames)) {
    # This function takes the original dataframe (dat, same one entered into runmod), the Bayesian model from brms (runmod), 
    # the configuration Name, and the variable you are testing. It returns:
    # [1] the probabality the variable was better in the test config vs. the baseline config
    # [3] the lower bound of the bayesian 95% posterior interval (as percent change from baseline) 
    # [4] the upper bound of the bayesian 95% posterior interval (as percent change from baseline)
    #i = 1
    
    configName = configNames[i]
    configColName <- paste('b_Config', configName, sep = "")
    posterior <- posterior_samples(mod)
    
    if (dir == 'lower'){
      prob <- sum(posterior[,configColName] < 0) / length(posterior[,configColName])
      
    } else if (dir == 'higher') {
      
      prob <- sum(posterior[,configColName] > 0) / length(posterior[,configColName])
    }
    
    ci <- posterior_interval(mod, prob = 0.80)
    ciLow <- ci[configColName,1] 
    ciHigh <- ci[configColName,2]
    
    SDdat <- dat %>%
      group_by(Subject) %>%
      summarize(sd = sd(!! sym(var), na.rm = TRUE), mean = mean(!! sym(var), na.rm = TRUE))
    
    meanSD = mean(SDdat$sd , na.rm = TRUE)
    mean = mean(SDdat$mean, na.rm = TRUE)
    ci_LowPct <- meanSD*ciLow/mean*100
    ci_HighPct <- meanSD*ciHigh/mean*100
    
    output = list('Config:', configName, 'Probability of Improvement:', prob, 'Worse end of CI:', ci_LowPct, 'Best end of CI:', ci_HighPct)
    Config[i] = configName
    ProbImp[i] = prob
    lowCI[i] = ci_LowPct
    highCI[i] = ci_HighPct
  }
  ProbImp = round(ProbImp*100)
  lowCI = round(lowCI, 1)
  highCI = round(highCI,1)
  output = cbind(Config, ProbImp, lowCI, highCI)
  
  colnames(output) = c('Config', 'Probability of Improvement', 'Low end of CI', 'High end of CI')
  
  sentences = rep(NA, nrow(output))
  
  for (i in 1:nrow(output)){
    if (as.numeric(output[i,2]) >= 90){
      sentences[i] <- paste0('We have meaningful confidence that ',output[i,1], ' outperformed ', baseConfig, ' (',output[i,2], '%)', '\n', '\t', '- Estimated difference: ',output[i,3],' to ',output[i,4],'%' )
    } else if (as.numeric(output[i,2]) >= 80) {      
      sentences[i] <- paste('We have moderate confidence that',output[i,1], 'outperformed', baseConfig, '(',output[i,2], '%)','\n', '\t', '- Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 70){
      sentences[i] <- paste('We have minimal confidence that',output[i,1], 'outperformed', baseConfig, '(',output[i,2], '%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 30){
      sentences[i] <- paste('There were inconsistent differences between',output[i,1],'and',baseConfig,'(',output[i,2],'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 20){
      sentences[i] <- paste('We have minimal confidence that',output[i,1],'performed worse than',baseConfig,'(',(100 - as.numeric(output[i,2])),'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 10){
      sentences[i] <- paste('We have moderate confidence that',output[i,1],'performed worse than',baseConfig,'(',(100 - as.numeric(output[i,2])),'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else {
      sentences[i] <- paste('We have meaningful confidence that',output[i,1],'performed worse than',baseConfig,'(',(100 - as.numeric(output[i,2])),'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    }
  }
  
  writeLines(sentences)
  return()
}

# Setting up  "Best Of" line plots 
withinSubQualPlot <- function(inputDF) {
  
  # direction can be 'lower' or higher'. It is the direction of change that is better. 
  # For example, for contact time lower is better. so we put 'lower'. for jump height, higher is better, so we put higher. 
  
  whichConfig <- inputDF %>%
    group_by(Subject) %>%
    summarize(
      BestConfig = Config[which.max(OverallFit)]
    )
  
  whichConfig <- merge(inputDF, whichConfig)
  
  ggplot(data = whichConfig, mapping = aes(x = as.factor(Config), y = OverallFit, col = BestConfig, group = Subject)) + geom_point(size = 4) + 
    geom_line() + xlab('Configuration') + scale_color_manual(values=c("#000000", "#00966C", "#ECE81A","#DC582A","#CAF0E4")) + ylab('Rating') + theme(text = element_text(size = 16))
  
}

###############################
```

**Qualitative**

```{r}
#| echo: false
#| warning: false

qualDat %>%
  pivot_longer(cols = OverallFit:Heel, 
               names_to = "Location", values_to = "Rating") %>%
  group_by(Location, Config) %>%
  summarize(
    avg = mean(Rating, na.rm = TRUE),
    medAvg = median(Rating, na.rm = TRUE)
  ) %>%
  gt()


#Defining the rating for the location 
#Density plots for fit ratings of shoe locations
qualDat <- pivot_longer(qualDat, cols = Forefoot:Heel, names_to = 'Location', values_to = 'Rating')

FF <- qualDat %>% 
  filter(Location=="Forefoot")


qualDat$Location <- factor(qualDat$Location, c('Forefoot', 'Midfoot', 'Heel')) 

```

```{r}
#| echo: false
withinSubQualPlot(qualDat)
ggplot(qualDat, mapping = aes(x = Rating, fill = Config)) + 
  geom_histogram(position = 'dodge', binwidth = 1) + facet_wrap(~Location) + scale_fill_manual(values=c("#999999", "#00966C", "#ECE81A","#DC582A","#CAF0E4")) +
  ylab('Responses') + theme(text=element_text(size=20)) + geom_vline(xintercept = 5, linewidth = 1)
```

**Dial Torque**

```{r}
#| echo: false
#| warning: false
qualDat %>%
  group_by(Config)%>%
  summarize(
    R_Torque_Prox = mean(R_DialTorque1, na.rm = TRUE),
    R_Torque_Dist = mean(R_DialTorque2, na.rm = TRUE),
    L_Torque_Prox = mean(L_DialTorque1, na.rm = TRUE),
    L_Torque_Dist = mean(L_DialTorque2, na.rm = TRUE)
  )%>%
  gt()

ggplot(qualDat, aes(x=Config, y = L_DialTorque1, color = Config, group= Subject)) + 
  geom_point(size = 4)+ 
  geom_line(aes(color=Config))+
  # facet_wrap(~Subject)+
  scale_color_manual(values=c("#000000","#00966C", "#ECE81A","#DC582A","#CAF0E4"))+ 
  theme(text = element_text(size = 16))+ 
  ylab('Proximal (instep) Dial - Torque [N-cm]')+ 
  xlab('Config')+
  ggtitle('Left Foot')

```

## Endurance

**Heart Rate: Lower is better**

```{r}
#| echo: false
#| warning: false
################

###### Heart Rate

HRdat1 <- HRdat %>% 
  group_by(Subject) %>%
  mutate(z_score = scale(AvgHRS1)) %>% 
  group_by(Config)

HRdat2 <- HRdat %>% 
  group_by(Subject) %>%
  mutate(z_score = scale(AvgHRS2)) %>% 
  group_by(Config)

HRdat3 <- HRdat %>% 
  group_by(Subject) %>%
  mutate(z_score = scale(AvgHRS3)) %>% 
  group_by(Config)


HRdat1Mod <- brm(data = HRdat1, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + 1| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


extractVals(HRdat1, HRdat1Mod, otherConfigs, baseline, 'AvgHRS1', 'lower') 

HRdat2Mod <- brm(data = HRdat2, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + 1| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


extractVals(HRdat2, HRdat2Mod, otherConfigs, baseline, 'AvgHRS2', 'lower') 

HRdat3Mod <- brm(data = HRdat3, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + 1| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


extractVals(HRdat3, HRdat3Mod, otherConfigs, baseline, 'AvgHRS3', 'lower')

# p <- withinSubPlot(HRdat1, colName = 'AvgHRS1', dir = 'lower')
# p + ylab('Uphill Heart Rate (bpm)')
# 
p <- withinSubPlot(HRdat2, colName = 'AvgHRS2', dir = 'lower')
p + ylab('Technical Top Heart Rate (bpm)')

p <- withinSubPlot(HRdat3, colName = 'AvgHRS3', dir = 'lower')
p + ylab('Downhill Heart Rate (bpm)')


```

**Running Speed: Higher is better**

```{r}
#| echo: false
#| warning: false
################

###### Running Speed

Speeddat1 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 1) %>%
  mutate(z_score = scale(imuSpeed)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Speeddat1, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject) 

Speeddat2 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 2) %>%
  mutate(z_score = scale(imuSpeed)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Speeddat2, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject)

Speeddat3 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 3) %>%
  mutate(z_score = scale(imuSpeed)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Speeddat3, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject)


# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
Speeddat1Mod <- brm(data = Speeddat1, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(Speeddat1, Speeddat1Mod, otherConfigs, baseline, 'imuSpeed', 'higher') 



# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
Speeddat2Mod <- brm(data = Speeddat2, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(Speeddat2, Speeddat2Mod, otherConfigs, baseline, 'imuSpeed', 'higher')  

# Note for trail run metrics: Warmup was reduced (from 1000 to 400)
Speeddat3Mod <- brm(data = Speeddat3, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 400, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(Speeddat3, Speeddat3Mod, otherConfigs, baseline, 'imuSpeed', 'higher') 

p <- withinSubPlot(Speeddat1, colName = 'imuSpeed', dir = 'higher')
p + ylab('Uphill Speed (m/s)')

p <- withinSubPlot(Speeddat2, colName = 'imuSpeed', dir = 'lower')
p + ylab('Technical Top Speed (m/s)')

p <- withinSubPlot(Speeddat3, colName = 'imuSpeed', dir = 'lower')
p + ylab('Downhill Speed (m/s)')


```

## Health

**Peak Eversion Velocity (ankle stability): Lower is better**

```{r}
#| echo: false
#| warning: false
################

###### Peak eversion velocity

Everdat1 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 1) %>%
  mutate(z_score = scale(pIEgyro)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Everdat1, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject)

Everdat2 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 2) %>%
  mutate(z_score = scale(pIEgyro)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Everdat2, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject)

Everdat3 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 3) %>%
  mutate(z_score = scale(pIEgyro)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Everdat3, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject)


# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
Everdat1Mod <- brm(data = Everdat1, # Bayes model
              family = gaussian,
              z_score ~ Config + imuSpeed + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(Everdat1, Everdat1Mod, otherConfigs, baseline, 'pIEgyro', 'lower')

# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
Everdat2Mod <- brm(data = Everdat2, # Bayes model
              family = gaussian,
              z_score ~ Config + imuSpeed + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(Everdat2, Everdat2Mod, otherConfigs, baseline, 'pIEgyro', 'lower')

# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
Everdat3Mod <- brm(data = Everdat3, # Bayes model
              family = gaussian,
              z_score ~ Config + imuSpeed + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(Everdat3, Everdat3Mod, otherConfigs, baseline, 'pIEgyro', 'lower')

p <- withinSubPlot(Everdat1, colName = 'pIEgyro', dir = 'lower')
p + ylab('Uphill Eversion Velcity (deg/s)')

p <- withinSubPlot(Everdat2, colName = 'pIEgyro', dir = 'lower')
p + ylab('Technical Top Eversion Velcity (deg/s)')

p <- withinSubPlot(Everdat3, colName = 'pIEgyro', dir = 'lower')
p + ylab('Downhill Eversion Velcity (deg/s)')

```

## Quantitative Fit

**Heel contact area (heel hold): Higher is better**

```{r}
#| echo: false
#| warning: false
################

###### Heel Contact

HeelCondat1 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 1, LoR == 'L') %>%
  mutate(z_score = scale(HeelCon)) %>% 
  group_by(Config)

HeelCondat1sub <- HeelCondat1 %>%
  group_by(Subject,Config) %>%
  sample_n(size = 200, replace = FALSE)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = HeelCondat1, aes(x = HeelCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)
# ggplot(data = HeelCondat1sub, aes(x = HeelCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

HeelCondat2 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 2, LoR == 'L') %>%
  mutate(z_score = scale(HeelCon)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = HeelCondat2, aes(x = HeelCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

HeelCondat3 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 3, LoR == 'L') %>%
  mutate(z_score = scale(HeelCon)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = HeelCondat3, aes(x = HeelCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
HeelCondat1Mod <- brm(data = HeelCondat1, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(HeelCondat1, HeelCondat1Mod, otherConfigs, baseline, 'HeelCon', 'higher')

HeelCondat2Mod <- brm(data = HeelCondat2, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(HeelCondat2, HeelCondat2Mod, otherConfigs, baseline, 'HeelCon', 'higher')

HeelCondat3Mod <- brm(data = HeelCondat3, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(HeelCondat3, HeelCondat3Mod, otherConfigs, baseline, 'HeelCon', 'higher')


p <- withinSubPlot(HeelCondat1, colName = 'HeelCon', dir = 'higher')
p + ylab('Uphill Heel Contact (%)')

p <- withinSubPlot(HeelCondat2, colName = 'HeelCon', dir = 'higher')
p + ylab('Technical Top Heel Contact (%)')

p <- withinSubPlot(HeelCondat3, colName = 'HeelCon', dir = 'higher')
p + ylab('Downhill Heel Contact (%)')
```

**Forefoot contact area (heel hold): Higher is better**

```{r}
#| echo: false
#| warning: false
################

###### Forefoot Contact

ForeCondat1 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 1, LoR == 'L') %>%
  mutate(z_score = scale(MetCon)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = ForeCondat1, aes(x = MetCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

ForeCondat2 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 2, LoR == 'L') %>%
  mutate(z_score = scale(MetCon)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = ForeCondat2, aes(x = MetCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

ForeCondat3 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 3, LoR == 'L') %>%
  mutate(z_score = scale(MetCon)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = ForeCondat3, aes(x = MetCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
ForeCondat1Mod <- brm(data = ForeCondat1, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(ForeCondat1, ForeCondat1Mod, otherConfigs, baseline, 'MetCon', 'higher')

# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
ForeCondat2Mod <- brm(data = ForeCondat2, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(ForeCondat2, ForeCondat2Mod, otherConfigs, baseline, 'MetCon', 'higher')

# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
ForeCondat3Mod <- brm(data = ForeCondat3, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

extractVals(ForeCondat3, ForeCondat3Mod, otherConfigs, baseline, 'MetCon', 'higher')

p <- withinSubPlot(ForeCondat1, colName = 'MetCon', dir = 'higher')
p + ylab('Uphill Forefoot Contact (%)')

p <- withinSubPlot(ForeCondat2, colName = 'MetCon', dir = 'higher')
p + ylab('Technical Top Forefoot Contact (%)')

p <- withinSubPlot(ForeCondat3, colName = 'MetCon', dir = 'higher')
p + ylab('Downhill Forefoot Contact (%)')
```

Radar Plots

```{r}
#| echo: false

###### For agility run combo
# For SDHL

Endurance <- 84

Health <- 23

Fit <- 37

Qual <- 91

data <- t(c(Endurance, Health, Fit, Qual))

data <- as.data.frame(data)

improvThresh<- as.data.frame(t(c(70,70,70,94)))
equalThresh<- as.data.frame(t(c(50,50,50,94)))

min =as.data.frame(t(rep(0, 4)))
max = as.data.frame(t(rep(100,4)))
data <- rbind(max, min, improvThresh, equalThresh, data)

colnames(data) <- c("Endurance", "Health", "Fit", "Qual")

colors <- c("#C8C9C7","#53565A", "#00966C")

create_beautiful_radarchart <- function(data, color = "#00966C",
                                        vlabels = colnames(data), vlcex = 0.9,
                                        caxislabels = NULL, title = NULL, ...){
  radarchart(
    data, axistype = 1,
    # Customize the polygon
    pcol = color, pfcol = scales::alpha(color, 0.5), plwd = 2, plty = 1,
    # Customize the grid
    cglcol = "grey", cglty = 1, cglwd = 0.8,
    # Customize the axis
    axislabcol = "grey",
    # Variable labels
    vlcex = vlcex, vlabels = vlabels,
    caxislabels = caxislabels, title = title, ...
  )
}


create_beautiful_radarchart(data = data, color = colors)

legend(x = "topright", inset = c(- 0.3, 0.2), legend = c("Threshold for confidence in improvement", "SD", "Heel Lock Config"),
       bty = "n", pch = 20, col = colors, text.col = "black", cex = .7, pt.cex = 1)
# 
# ## This code gives a visual representation of how a shoe performed against a baseline shoe in the form of a radar plot 
# #This happens by assigning different averaged ratings to different segments 
# #You are only adding the shoe being tested to the ratings, the baseline shoe is always set to 50 for a clear comparison
# #The shoe being tested is rated by the average percentile confidence in each segment 
# ###For example, if a PFS shoe had 75% confidence in CMJ  and 50% in skater for contact time, the average rating for agility would be 62.5 -> 63 
# 
# 
# 
# #### Config DDHL
# 
Endurance <- 81

Health <- 27

Fit <- 75

Qual <- 96

data <- t(c(Endurance, Health, Fit, Qual))

data <- as.data.frame(data)

improvThresh<- as.data.frame(t(c(70,70,70,94)))
equalThresh<- as.data.frame(t(c(50,50,50,94)))

min =as.data.frame(t(rep(0, 4)))
max = as.data.frame(t(rep(100,4)))
data <- rbind(max, min, improvThresh, equalThresh, data)

colnames(data) <- c("Endurance", "Health", "Fit", "Qual")

colors <- c("#C8C9C7","#53565A", "#00966C")

create_beautiful_radarchart <- function(data, color = "#00966C",
                                        vlabels = colnames(data), vlcex = 0.9,
                                        caxislabels = NULL, title = NULL, ...){
  radarchart(
    data, axistype = 1,
    # Customize the polygon
    pcol = color, pfcol = scales::alpha(color, 0.5), plwd = 2, plty = 1,
    # Customize the grid
    cglcol = "grey", cglty = 1, cglwd = 0.8,
    # Customize the axis
    axislabcol = "grey",
    # Variable labels
    vlcex = vlcex, vlabels = vlabels,
    caxislabels = caxislabels, title = title, ...
  )
}


create_beautiful_radarchart(data = data, color = colors)

legend(x = "topright", inset = c(- 0.3, 0.2), legend = c("Threshold for confidence in improvement", "SD", "Heel Lock Config"),
       bty = "n", pch = 20, col = colors, text.col = "black", cex = .7, pt.cex = 1)
```
