---
title: "PFL DATA REPORT"
format: 
  docx:
    reference-doc: 'C:/Users/eric.honert/Boa Technology Inc/PFL Team - General/Testing Segments/Report_Template.docx'
editor: visual
editor_options: 
  chunk_output_type: console
execute: 
  error: true
  warning: false
---

# CONFIDENTAL CONTENT FOR BOA EMPLOYEES ONLY. PLEASE CONTACT PFL DIRECTLY WITH ANY QUESTIONS.

+--------------------+-----------------------------------+
| Test Name          | EH_Trail_HeelLockTrail_Perf_May23 |
+====================+===================================+
| **Segment:**       | Outdoor: Trail Run                |
+--------------------+-----------------------------------+
| **Date:**          | 5/2023                            |
+--------------------+-----------------------------------+
| **Test Type:**     | Performance                       |
+--------------------+-----------------------------------+
| **Configurations** | Baseline: SD (Single Dial)        |
|                    |                                   |
|                    | Test configurations:              |
|                    |                                   |
|                    | -   SDHL (Single Dial Heel-Lock)  |
|                    |                                   |
|                    | -   DDHL (Dual Dial Heel-Lock)    |
+--------------------+-----------------------------------+

# Purpose & Background

-   Previous cycling performance tests (Cycling_DDRoad_Performance_Feb22) showed improvements due to a heel lock guide providing immediate lace pull toward the heel cut.

-   In-lab testing demonstrated that the single-dial heel lock improved quantitative fit; but neither heel lock configuration improved agility performance

-   **The purpose of this test was to evaluate how a heel lock guide affects endurance and health performance in a single dial and dual dial configuration on trail.**

# Hypothesis

**Key Benefits:**

H1: The heel lock will improve heel hold and the dual dial heel lock will provide the best fit. Heel hold will be measured as contact area between the heel and the midsole during trail running. The heel hold will be evaluated during uphill, technical, and downhill running

H2: The heel lock will improve ankle stability with dual dial heel lock providing the most stability. Ankle stability will be measured as the peak eversion velocity.

**Additional Benefits:**

H3: The heel lock will improve running speed with no change in heart rate. The dual dial will provide the most improvement.

# Methods

+------------------+---------------+------------------+----------------------------+
| Subjects         | Movements     | Equipment        | Measurements               |
+==================+===============+==================+============================+
| 10 Male Athletes | Trail Running | Pressure insoles | Endurance:                 |
|                  |               |                  |                            |
|                  |               |                  | -   Running speed          |
|                  |               |                  |                            |
|                  |               |                  | -   Heart Rate             |
|                  |               |                  |                            |
|                  |               |                  | Health:                    |
|                  |               |                  |                            |
|                  |               |                  | -   Peak eversion velocity |
|                  |               |                  |                            |
|                  |               |                  | Fit:                       |
|                  |               |                  |                            |
|                  |               |                  | -   Heel contact area      |
|                  |               |                  |                            |
|                  |               |                  | -   Forefoot pressure      |
+------------------+---------------+------------------+----------------------------+

# Configurations

+-----------------------------+------------------------------+-----------------------------+
| Baseline: Single Dial (SD)  | Single Dial Heel Lock (SDHL) | Dual Dial Heel Lock (DDHL)  |
+=============================+==============================+=============================+
| ![](images/config1_LAT.png) | ![](images/config2_LAT.png)  | ![](images/config3_LAT.png) |
+-----------------------------+------------------------------+-----------------------------+

```{r}
#| echo: false
#| warning: false
#| include: false

library(readxl)
library(tidyverse)
library(lme4)
library(emmeans)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
library(readxl)
library(brms)
library(patchwork)
library(tidyr)
library(fmsb)
library(gt)
rm(list=ls())
```

```{r}
#| echo: false
#| warning: false
#| include: false

#Load in Compiled Qualitative Sheet
qualDat <- read_xlsx('C:/Users/eric.honert/Boa Technology Inc/PFL Team - General/Testing Segments/EndurancePerformance/EH_Trail_HeelLockTrail_Perf_May23/Qual_EH_Trail_HeelLockTrail_Perf_May23.xlsx')

# Load in the heart rate data
HRdat <- read.csv('C:/Users/eric.honert/Boa Technology Inc/PFL Team - General/Testing Segments/EndurancePerformance/EH_Trail_HeelLockTrail_Perf_May23/Watch/CombinedGPS.csv')

# Load in the IMU data
IMUdat <- read.csv('C:/Users/eric.honert/Boa Technology Inc/PFL Team - General/Testing Segments/EndurancePerformance/EH_Trail_HeelLockTrail_Perf_May23/IMU/IMUmetrics.csv')

# Load in the insole data
Pressdat <- read.csv('C:/Users/eric.honert/Boa Technology Inc/PFL Team - General/Testing Segments/EndurancePerformance/EH_Trail_HeelLockTrail_Perf_May23/Xsensor/PressureOutcomes.csv')


baseline <- 'SD' # baseline configuration

otherConfigs <- c('SDHL', 'DDHL') # other configurations tested against base
allConfigs <- c(baseline, otherConfigs)


qualDat$Config <- factor(qualDat$Config, allConfigs)


HRdat <- as_tibble(HRdat) # creating the data frame
HRdat$Config <- factor(HRdat$Config, allConfigs)

IMUdat <- as_tibble(IMUdat) # creating the data frame
IMUdat$Config <- factor(IMUdat$Config, allConfigs)

Pressdat <- as_tibble(Pressdat) # creating the data frame
Pressdat$Config <- factor(Pressdat$Config, allConfigs)


# updated withinAvg plot 
withinSubPlotAvg <- function(inputDF, colName, dir = 'lower', yLabel = NULL) {
  # Validate the `dir` input
  if(!dir %in% c('lower', 'higher')){
    stop("The 'dir' argument must be either 'lower' or 'higher'.")
  }
  # Calculate the mean for each Subject and Config, removing NA values
  meanDat <- inputDF %>%
    group_by(Subject, Config) %>%
    summarize(mean = mean(!! sym(colName), na.rm = TRUE), .groups = 'drop')
  # Determine the best configuration based on the direction
  if (dir == 'lower'){
    whichConfig <- meanDat %>%
      group_by(Subject) %>%
      reframe(BestConfig = Config[which.min(mean)])
  } else if (dir == 'higher') {
    whichConfig <- meanDat %>%
      group_by(Subject) %>%
      reframe(BestConfig = Config[which.max(mean)])
  }
  # Rename BestConfig to Config for merging
  whichConfig <- whichConfig %>%
    rename(Config = BestConfig)
  # Merge the best configuration back to the mean data
  mergedData <- merge(meanDat, whichConfig, by = c("Subject", "Config"))
  # Calculate overall mean for each Config, removing NA values
  overallMean <- meanDat %>%
    group_by(Config) %>%
    summarize(overallMean = mean(mean, na.rm = TRUE), .groups = 'drop')
  # Plotting with ggplot2
  plot <- ggplot() +
    geom_point(data = meanDat, mapping = aes(x = as.factor(Config), y = mean, group = Subject, color = 'Subject Means'), size = 3, alpha = 0.5) +
    geom_line(data = meanDat, mapping = aes(x = as.factor(Config), y = mean, group = Subject, color = 'Subject Means'), alpha = 0.5) +
    geom_point(data = overallMean, mapping = aes(x = as.factor(Config), y = overallMean, color = 'Overall Mean'), size = 4, shape = 17) +
    geom_line(data = overallMean, mapping = aes(x = as.factor(Config), y = overallMean, group = 1, color = 'Overall Mean'), size = 1.5) +
    scale_color_manual(values = c('Subject Means' = 'grey', 'Overall Mean' = '#003C4C')) +
    xlab('Configuration') +
    theme(text = element_text(size = 16), legend.title = element_blank())
  # Set y-axis label
  if (!is.null(yLabel)) {
    plot <- plot + ylab(yLabel)
  } else {
    plot <- plot + ylab(paste0(colName))
  }
  print(plot)
}


extractVals <- function(dat, mod, configNames, baseConfig, var, dir) {
  
  Config = rep(NA, length(configNames))
  ProbImp = matrix(0, length(configNames))
  lowCI = matrix(0, length(configNames))
  highCI = matrix(0, length(configNames))
  
  for (i in 1:length(configNames)) {
    # This function takes the original dataframe (dat, same one entered into runmod), the Bayesian model from brms (runmod), 
    # the configuration Name, and the variable you are testing. It returns:
    # [1] the probabality the variable was better in the test config vs. the baseline config
    # [3] the lower bound of the bayesian 95% posterior interval (as percent change from baseline) 
    # [4] the upper bound of the bayesian 95% posterior interval (as percent change from baseline)
    #i = 1
    
    configName = configNames[i]
    configColName <- paste('b_Config', configName, sep = "")
    posterior <- posterior_samples(mod)
    
    if (dir == 'lower'){
      prob <- sum(posterior[,configColName] < 0) / length(posterior[,configColName])
      
    } else if (dir == 'higher') {
      
      prob <- sum(posterior[,configColName] > 0) / length(posterior[,configColName])
    }
    
    ci <- posterior_interval(mod, prob = 0.80)
    ciLow <- ci[configColName,1] 
    ciHigh <- ci[configColName,2]
    
    SDdat <- dat %>%
      group_by(Subject) %>%
      summarize(sd = sd(!! sym(var), na.rm = TRUE), mean = mean(!! sym(var), na.rm = TRUE))
    
    meanSD = mean(SDdat$sd , na.rm = TRUE)
    mean = mean(SDdat$mean, na.rm = TRUE)
    ci_LowPct <- meanSD*ciLow/mean*100
    ci_HighPct <- meanSD*ciHigh/mean*100
    
    output = list('Config:', configName, 'Probability of Improvement:', prob, 'Worse end of CI:', ci_LowPct, 'Best end of CI:', ci_HighPct)
    Config[i] = configName
    ProbImp[i] = prob
    lowCI[i] = ci_LowPct
    highCI[i] = ci_HighPct
  }
  ProbImp = round(ProbImp*100)
  lowCI = round(lowCI, 1)
  highCI = round(highCI,1)
  output = cbind(Config, ProbImp, lowCI, highCI)
  
  colnames(output) = c('Config', 'Probability of Improvement', 'Low end of CI', 'High end of CI')
  
  sentences = rep(NA, nrow(output))
  
  for (i in 1:nrow(output)){
    if (as.numeric(output[i,2]) >= 90){
      sentences[i] <- paste0('We have meaningful confidence that ',output[i,1], ' outperformed ', baseConfig, ' (',output[i,2], '%)', '\n', '\t', '- Estimated difference: ',output[i,3],' to ',output[i,4],'%' )
    } else if (as.numeric(output[i,2]) >= 80) {      
      sentences[i] <- paste('We have moderate confidence that',output[i,1], 'outperformed', baseConfig, '(',output[i,2], '%)','\n', '\t', '- Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 70){
      sentences[i] <- paste('We have minimal confidence that',output[i,1], 'outperformed', baseConfig, '(',output[i,2], '%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 30){
      sentences[i] <- paste('There were inconsistent differences between',output[i,1],'and',baseConfig,'(',output[i,2],'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 20){
      sentences[i] <- paste('We have minimal confidence that',output[i,1],'performed worse than',baseConfig,'(',(100 - as.numeric(output[i,2])),'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 10){
      sentences[i] <- paste('We have moderate confidence that',output[i,1],'performed worse than',baseConfig,'(',(100 - as.numeric(output[i,2])),'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else {
      sentences[i] <- paste('We have meaningful confidence that',output[i,1],'performed worse than',baseConfig,'(',(100 - as.numeric(output[i,2])),'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    }
  }
  
  writeLines(sentences)
  return()
}



# qual average plot
withinSubQualAvg <- function(inputDF) {
  
  # direction can be 'lower' or higher'. It is the direction of change that is better. 
  # For example, for contact time lower is better. so we put 'lower'. for jump height, higher is better, so we put higher. 
  # Calculate the mean for each Subject and Config, removing NA values
  meanDat <- inputDF %>%
    group_by(Subject, Config) %>%
    summarize(mean = mean(OverallFit, na.rm = TRUE), .groups = 'drop')
  
  
  whichConfig <- inputDF %>%
    group_by(Subject) %>%
    summarize(
      BestConfig = Config[which.max(OverallFit)]
    )
  
  whichConfig <- whichConfig %>%
    rename(Config = BestConfig)
  
  mergeDat <- merge(meanDat, whichConfig)
  
  overallMean <- meanDat %>%
    group_by(Config) %>%
    summarize(overallMean = mean(mean, na.rm = TRUE), .groups = 'drop')
  # Plotting with ggplot2
  plot <- ggplot() +
    geom_point(data = meanDat, mapping = aes(x = as.factor(Config), y = mean, group = Subject, color = 'Subject Means'), size = 3, alpha = 0.5) +
    geom_line(data = meanDat, mapping = aes(x = as.factor(Config), y = mean, group = Subject, color = 'Subject Means'), alpha = 0.5) +
    geom_point(data = overallMean, mapping = aes(x = as.factor(Config), y = overallMean, color = 'Overall Mean'), size = 4, shape = 17) +
    geom_line(data = overallMean, mapping = aes(x = as.factor(Config), y = overallMean, group = 1, color = 'Overall Mean'), linewidth = 1.5) +
    scale_color_manual(values = c('Subject Means' = 'grey', 'Overall Mean' = '#003C4C')) +
    xlab('Configuration') + ylab('Rating') +
    theme(text = element_text(size = 16), legend.title = element_blank()) 
    
  
  print(plot)
  
}

withinSubQualAvg(qualDat)

EffectSizeLM <- function(df, inputmodel) {
  myformula <- as.formula(paste0(inputmodel))
  full.mod = lmer(myformula, data = df, REML = TRUE, na.action = "na.omit")
  conditions.emm <- emmeans(full.mod, "Config", lmer.df = "satterthwaite")
  efsi_sum = summary(eff_size(conditions.emm, sigma = sigma(full.mod), edf = Inf))
  
  for (ii in 1:(length(unique(df$Config))-1)){
    print(paste('effect size for:', efsi_sum$contrast[ii], ' is ', round(efsi_sum$effect.size[ii],3)))
  }

return()
}
```

# Summary of Findings

(Did we achieve the goal of the study?)

# Next Steps

-   

# Recommendations

-   

# Key Benefit Performance

|                             | Base | Config1 | Config2 |
|-----------------------------|------|---------|---------|
| Power Transfer              | 50   |         |         |
| Energy Efficiency           | 50   |         |         |
| Stability & Control         | 50   |         |         |
| Quantitative Fit            | 50   |         |         |
| Overall Performance Ranking | 50   |         |         |

# Additional Benefit Performance

|                     | Base | Config1 | Config2 |
|---------------------|------|---------|---------|
| Qualitative Ranking | 90   |         |         |

# **Qualitative**

```{r}
#| echo: false
#| warning: false
#| include: true 
#| layout-ncol: 2  

qualDat %>%
  pivot_longer(cols = OverallFit:Heel, 
               names_to = "Location", values_to = "Rating") %>%
  group_by(Location, Config) %>%
  summarize(
    avg = mean(Rating, na.rm = TRUE),
    medAvg = median(Rating, na.rm = TRUE)
  ) %>%
  gt()


#Defining the rating for the location 
#Density plots for fit ratings of shoe locations
qualDat <- pivot_longer(qualDat, cols = Forefoot:Heel, names_to = 'Location', values_to = 'Rating')

FF <- qualDat %>% 
  filter(Location=="Forefoot")


qualDat$Location <- factor(qualDat$Location, c('Forefoot', 'Midfoot', 'Heel')) 

```

```{r}
#| echo: false
#| warning: false
#| include: true

withinSubQualAvg(qualDat)
ggplot(qualDat, mapping = aes(x = Rating, fill = Config)) + 
  geom_histogram(position = 'dodge', binwidth = 1) + facet_wrap(~Location) + scale_fill_manual(values=c("#999999", "#00966C", "#ECE81A","#DC582A","#CAF0E4")) +
  ylab('Responses') + theme(text=element_text(size=20)) + geom_vline(xintercept = 5, linewidth = 1)
```

## **Dial Torque**

```{r}
#| echo: false
#| warning: false
#| include: false

qualDat %>%
  group_by(Config)%>%
  summarize(
    R_Torque_Prox = mean(R_DialTorque1, na.rm = TRUE),
    R_Torque_Dist = mean(R_DialTorque2, na.rm = TRUE),
    L_Torque_Prox = mean(L_DialTorque1, na.rm = TRUE),
    L_Torque_Dist = mean(L_DialTorque2, na.rm = TRUE)
  )%>%
  gt()

ggplot(qualDat, aes(x=Config, y = L_DialTorque1, color = Config, group= Subject)) + 
  geom_point(size = 4)+ 
  geom_line(aes(color=Config))+
  # facet_wrap(~Subject)+
  scale_color_manual(values=c("#000000","#00966C", "#ECE81A","#DC582A","#CAF0E4"))+ 
  theme(text = element_text(size = 16))+ 
  ylab('Proximal (instep) Dial - Torque [N-cm]')+ 
  xlab('Config')+
  ggtitle('Left Foot')

```

```{r}
#| echo: false
#| warning: false
#| include: true 

torqueDat <- qualDat %>%
  group_by(Subject) %>%
  mutate(z_score = scale(L_DialTorque1)) %>%
  group_by(Config)


torqueMod <- brm(data = torqueDat, # Bayes model
              family = gaussian,
              z_score ~  Config + (1  | Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


extractVals(torqueDat , torqueMod, otherConfigs, baseline, 'L_DialTorque1', 'higher')
```

# Endurance

## **Heart Rate: Lower is better**

```{r}
#| echo: false
#| warning: false
#| include: false


################

###### Heart Rate

HRdat1 <- HRdat %>% 
  group_by(Subject) %>%
  mutate(z_score = scale(AvgHRS1)) %>% 
  group_by(Config)

HRdat2 <- HRdat %>% 
  group_by(Subject) %>%
  mutate(z_score = scale(AvgHRS2)) %>% 
  group_by(Config)

HRdat3 <- HRdat %>% 
  group_by(Subject) %>%
  mutate(z_score = scale(AvgHRS3)) %>% 
  group_by(Config)


HRdat1Mod <- brm(data = HRdat1, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + 1| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)




HRdat2Mod <- brm(data = HRdat2, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + 1| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)




HRdat3Mod <- brm(data = HRdat3, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + 1| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)




```

```{r}
#| echo: false
#| warning: false
#| include: true
#| layout-ncol: 2 


extractVals(HRdat1, HRdat1Mod, otherConfigs, baseline, 'AvgHRS1', 'lower') 

extractVals(HRdat2, HRdat2Mod, otherConfigs, baseline, 'AvgHRS2', 'lower') 

extractVals(HRdat3, HRdat3Mod, otherConfigs, baseline, 'AvgHRS3', 'lower')

p <- withinSubPlotAvg(HRdat1, colName = 'AvgHRS1', dir = 'lower')
p + ylab('Uphill Heart Rate (bpm)')

EffectSizeLM(HRdat1,'AvgHRS1 ~ Config + (Config|Subject)')

p <- withinSubPlotAvg(HRdat2, colName = 'AvgHRS2', dir = 'lower')
p + ylab('Technical Top Heart Rate (bpm)')

p <- withinSubPlotAvg(HRdat3, colName = 'AvgHRS3', dir = 'lower')
p + ylab('Downhill Heart Rate (bpm)')

```

## **Running Speed: Higher is better**

```{r}
#| echo: false
#| warning: false
#| include: false


################

###### Running Speed

Speeddat1 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 1) %>%
  mutate(z_score = scale(imuSpeed)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Speeddat1, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject) 

Speeddat2 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 2) %>%
  mutate(z_score = scale(imuSpeed)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Speeddat2, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject)

Speeddat3 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 3) %>%
  mutate(z_score = scale(imuSpeed)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Speeddat3, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject)


# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
Speeddat1Mod <- brm(data = Speeddat1, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)




# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
Speeddat2Mod <- brm(data = Speeddat2, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

 

# Note for trail run metrics: Warmup was reduced (from 1000 to 400)
Speeddat3Mod <- brm(data = Speeddat3, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 400, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)




```

```{r}
#| echo: false
#| warning: false
#| include: true
#| layout-ncol: 2 

extractVals(Speeddat1, Speeddat1Mod, otherConfigs, baseline, 'imuSpeed', 'higher') 

extractVals(Speeddat2, Speeddat2Mod, otherConfigs, baseline, 'imuSpeed', 'higher') 

extractVals(Speeddat3, Speeddat3Mod, otherConfigs, baseline, 'imuSpeed', 'higher') 

p <- withinSubPlotAvg(Speeddat1, colName = 'imuSpeed', dir = 'higher')
p + ylab('Uphill Speed (m/s)')

p <- withinSubPlotAvg(Speeddat2, colName = 'imuSpeed', dir = 'higher')
p + ylab('Technical Top Speed (m/s)')

p <- withinSubPlotAvg(Speeddat3, colName = 'imuSpeed', dir = 'higher')
p + ylab('Downhill Speed (m/s)')
```

# Health

## **Peak Eversion Velocity (ankle stability): Lower is better**

```{r}
#| echo: false
#| warning: false
#| include: false


################

###### Peak eversion velocity

Everdat1 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 1) %>%
  mutate(z_score = scale(pIEgyro)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Everdat1, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject)

Everdat2 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 2) %>%
  mutate(z_score = scale(pIEgyro)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Everdat2, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject)

Everdat3 <- IMUdat %>% 
  group_by(Subject) %>%
  filter(Label == 3) %>%
  mutate(z_score = scale(pIEgyro)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = Everdat3, aes(x = imuSpeed, color = Config)) + geom_histogram() + facet_wrap(~Subject)


# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
Everdat1Mod <- brm(data = Everdat1, # Bayes model
              family = gaussian,
              z_score ~ Config + imuSpeed + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)



# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
Everdat2Mod <- brm(data = Everdat2, # Bayes model
              family = gaussian,
              z_score ~ Config + imuSpeed + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
Everdat3Mod <- brm(data = Everdat3, # Bayes model
              family = gaussian,
              z_score ~ Config + imuSpeed + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


```

```{r}
#| echo: false
#| warning: false
#| include: true
#| layout-ncol: 2 


extractVals(Everdat1, Everdat1Mod, otherConfigs, baseline, 'pIEgyro', 'lower')

extractVals(Everdat2, Everdat2Mod, otherConfigs, baseline, 'pIEgyro', 'lower')

extractVals(Everdat3, Everdat3Mod, otherConfigs, baseline, 'pIEgyro', 'lower')

p <- withinSubPlotAvg(Everdat1, colName = 'pIEgyro', dir = 'lower')
p + ylab('Uphill Eversion Velcity (deg/s)')

p <- withinSubPlotAvg(Everdat2, colName = 'pIEgyro', dir = 'lower')
p + ylab('Technical Top Eversion Velcity (deg/s)')

p <- withinSubPlotAvg(Everdat3, colName = 'pIEgyro', dir = 'lower')
p + ylab('Downhill Eversion Velcity (deg/s)')

```

# Quantitative Fit

## **Heel contact area (heel hold): Higher is better**

```{r}
#| echo: false
#| warning: false
#| include: false


################

###### Heel Contact

HeelCondat1 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 1, LoR == 'L') %>%
  mutate(z_score = scale(HeelCon)) %>% 
  group_by(Config)

HeelCondat1sub <- HeelCondat1 %>%
  group_by(Subject,Config) %>%
  sample_n(size = 200, replace = FALSE)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = HeelCondat1, aes(x = HeelCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)
# ggplot(data = HeelCondat1sub, aes(x = HeelCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

HeelCondat2 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 2, LoR == 'L') %>%
  mutate(z_score = scale(HeelCon)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = HeelCondat2, aes(x = HeelCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

HeelCondat3 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 3, LoR == 'L') %>%
  mutate(z_score = scale(HeelCon)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = HeelCondat3, aes(x = HeelCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
HeelCondat1Mod <- brm(data = HeelCondat1, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)



HeelCondat2Mod <- brm(data = HeelCondat2, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)



HeelCondat3Mod <- brm(data = HeelCondat3, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


```

```{r}
#| echo: false
#| warning: false
#| include: true
#| layout-ncol: 2 


extractVals(HeelCondat1, HeelCondat1Mod, otherConfigs, baseline, 'HeelCon', 'higher')

extractVals(HeelCondat2, HeelCondat2Mod, otherConfigs, baseline, 'HeelCon', 'higher')

extractVals(HeelCondat3, HeelCondat3Mod, otherConfigs, baseline, 'HeelCon', 'higher')


p <- withinSubPlotAvg(HeelCondat1, colName = 'HeelCon', dir = 'higher')
p + ylab('Uphill Heel Contact (%)')

p <- withinSubPlotAvg(HeelCondat2, colName = 'HeelCon', dir = 'higher')
p + ylab('Technical Top Heel Contact (%)')

p <- withinSubPlotAvg(HeelCondat3, colName = 'HeelCon', dir = 'higher')
p + ylab('Downhill Heel Contact (%)')

```

## **Forefoot contact area (heel hold): Higher is better**

```{r}
#| echo: false
#| warning: false
#| include: false

################

###### Forefoot Contact

ForeCondat1 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 1, LoR == 'L') %>%
  mutate(z_score = scale(MetCon)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = ForeCondat1, aes(x = MetCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

ForeCondat2 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 2, LoR == 'L') %>%
  mutate(z_score = scale(MetCon)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = ForeCondat2, aes(x = MetCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

ForeCondat3 <- Pressdat %>% 
  group_by(Subject) %>%
  filter(Label == 3, LoR == 'L') %>%
  mutate(z_score = scale(MetCon)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
# ggplot(data = ForeCondat3, aes(x = MetCon, color = Config)) + geom_histogram() + facet_wrap(~Subject)

# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
ForeCondat1Mod <- brm(data = ForeCondat1, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
ForeCondat2Mod <- brm(data = ForeCondat2, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
ForeCondat3Mod <- brm(data = ForeCondat3, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 500, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


```

```{r}
#| echo: false
#| warning: false
#| include: true
#| layout-ncol: 2 

extractVals(ForeCondat1, ForeCondat1Mod, otherConfigs, baseline, 'MetCon', 'higher')

extractVals(ForeCondat2, ForeCondat2Mod, otherConfigs, baseline, 'MetCon', 'higher')

extractVals(ForeCondat3, ForeCondat3Mod, otherConfigs, baseline, 'MetCon', 'higher')

p <- withinSubPlotAvg(ForeCondat1, colName = 'MetCon', dir = 'higher')
p + ylab('Uphill Forefoot Contact (%)')

p <- withinSubPlotAvg(ForeCondat2, colName = 'MetCon', dir = 'higher')
p + ylab('Technical Top Forefoot Contact (%)')

p <- withinSubPlotAvg(ForeCondat3, colName = 'MetCon', dir = 'higher')
p + ylab('Downhill Forefoot Contact (%)')

```
