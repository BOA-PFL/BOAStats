---
title: "PFL DATA REPORT"
format: 
  docx:
    reference-doc: 'C:/Users/bethany.kilpatrick/Boa Technology Inc/PFL - General/Testing Segments/Report_Template.docx'
editor: visual
editor_options: 
  chunk_output_type: console 
execute: 
  error: true
  warning: false
---

# CONFIDENTAL CONTENT FOR BOA EMPLOYEES ONLY. PLEASE CONTACT PFL DIRECTLY WITH ANY QUESTIONS.

+--------------------+-----------------------------------------+
| Test Name          | EH_Workwear_MidcutStability3_Mech_Jan24 |
+====================+=========================================+
| **Benefit:**       | Endurance & Health                      |
+--------------------+-----------------------------------------+
| **Date:**          | 1/2024                                  |
+--------------------+-----------------------------------------+
| **Test Type:**     | Performance                             |
+--------------------+-----------------------------------------+
| **Configurations** | Baseline: External Ankle Guide (EXT)    |
|                    |                                         |
|                    | Test configurations:                    |
|                    |                                         |
|                    | -   Medial Wrap (Med)                   |
|                    |                                         |
|                    | -   Lateral Wrap (Lat)                  |
+--------------------+-----------------------------------------+

## Purpose & Background

-   Previous tests(MidcutStabilityII_CPDMech_Sept23, etc.) showed an external ankle wrap improved ankle stability metrics. It also performed the best in endurance metrics.

-   Learnings from high cut footwear established that the cuff alters ankle stability while the midfoot/lower zone controls heel hold.

-   Material A&S test (EnergyReturnA&S_April23) suggested that the direction of wrapping - medial v lateral - had a larger impact on performance than material choice in an unstructured shoe, with medial wrapping configurations performing best in A&S.

-   The purpose of this test was to understand if a medial or lateral ankle wrap affects endurance and health performance in high cut footwear.

## Hypothesis

H1: All three configurations will provide similar fit, increased heel hold and decreased toe pressures. Heel hold will be measured as contact area between the heel and the midsole during trail walking. Peak toe pressures will be measured during trail walking and during single leg landings on both level and uneven terrain.

H2: The medial wrap will improve ankle stability. Ankle stability will be measured as the peak eversion velocity.

H3: Similarly, the medial wrap will provide better balance with faster stabilizing times.

## Methods

+--------------+------------------------+---------------------------------------+----------------------------+
| Subjects     | Movements              | Equipment                             | Measurements               |
+==============+========================+=======================================+============================+
| 10 Athletes  | Uneven terrain walking | -   Pressure insoles                  | Efficiency:                |
|              |                        |                                       |                            |
| -   9 Male   |                        | -   Inertial Measurement Units (IMUs) | -   Walking Speed          |
|              |                        |                                       |                            |
| -   1 Female |                        |                                       | Stability:                 |
|              |                        |                                       |                            |
|              |                        |                                       | -   Peak eversion velocity |
|              |                        |                                       |                            |
|              |                        |                                       | Fit:                       |
|              |                        |                                       |                            |
|              |                        |                                       | -   Heel contact area      |
|              |                        |                                       | -   Peak toe pressure      |
+--------------+------------------------+---------------------------------------+----------------------------+
|              | Single Leg Landings    | -   In-ground force plates            | Stability:                 |
|              |                        |                                       |                            |
|              | -   On Trail           | -   Motion Capture cameras            | -   Time-to-stabilize      |
+--------------+------------------------+---------------------------------------+----------------------------+
|              | Treadmill Walking      |                                       | Efficiency:                |
|              |                        |                                       |                            |
|              | -   Uphill             |                                       | -   Center of mass work    |
|              |                        |                                       |                            |
|              | -   Downhill           |                                       |                            |
+--------------+------------------------+---------------------------------------+----------------------------+

## Configurations

+--------------------+----------------+----------------+
| Baseline: External | Medial Wrap    | Lateral Wrap   |
+====================+================+================+
|                    |                |                |
+--------------------+----------------+----------------+

## Summary of Findings

```{r}
#| echo: false
#| warning: false
#| include: false


library(readxl)
library(tidyverse)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
library(readxl)
library(brms)
library(patchwork)
library(tidyr)
library(fmsb)
library(gt)
library(ggplot2)
library(lme4)
rm(list=ls())
```

```{r}
#| echo: false
#| include: false

#Load in Compiled Qualitative Sheet
qualDat <- read_xlsx('C:/Users/bethany.kilpatrick/Boa Technology Inc/PFL - General/Testing Segments/Hike/EH_Hike_MidcutSD_Mech_April2024/EH_Hike_MidcutSD_Mech_April2024.xlsx')

# Load in the overground landing data
OGLandDat <- read.csv('C:\\Users\\bethany.kilpatrick\\Boa Technology Inc\\PFL - General\\Testing Segments\\Hike\\EH_Hike_MidcutSD_Mech_April2024\\Overground\\0_Stabilization.csv')


# Pressure Walking on Trail
PressWalkDat <- read.csv('C:\\Users\\bethany.kilpatrick\\Boa Technology Inc\\PFL - General\\Testing Segments\\Hike\\EH_Hike_MidcutSD_Mech_April2024\\Xsensor\\0_CompiledResults_Trail.csv')


# Load in the IMU trail SLL landing data
UnLandDat <- read.csv('C:\\Users\\bethany.kilpatrick\\Boa Technology Inc\\PFL - General\\Testing Segments\\Hike\\EH_Hike_MidcutSD_Mech_April2024\\IMU\\SLL\\0_TrailStabilize.csv')

# Load in the IMU data - trail walking
IMUdat_Trail <- read.csv('C:\\Users\\bethany.kilpatrick\\Boa Technology Inc\\PFL - General\\Testing Segments\\Hike\\EH_Hike_MidcutSD_Mech_April2024\\IMU\\Trail\\0_Trail_CompIMUmetrics.csv')


# Static Pressure
Static <- read.csv('C:\\Users\\bethany.kilpatrick\\Boa Technology Inc\\PFL - General\\Testing Segments\\Hike\\EH_Hike_MidcutSD_Mech_April2024\\Xsensor\\Static\\0_CompiledResults_Static.csv')


treadmill <- read.csv("C:\\Users\\bethany.kilpatrick\\Boa Technology Inc\\PFL - General\\Testing Segments\\Hike\\EH_Hike_MidcutSD_Mech_April2024\\Treadmill\\0_TreadmillOutcomes_test.csv")

baseline <- 'PFS' # baseline configuration

otherConfigs <- c('CF', 'IF') # other configurations tested against base
allConfigs <- c(baseline, otherConfigs)

qualDat$Config <- factor(qualDat$Config, allConfigs)

OGLandDat <- as_tibble(OGLandDat) # creating the data frame
OGLandDat$Config <- factor(OGLandDat$Config, allConfigs)


PressWalkDat <- as_tibble(PressWalkDat) # creating the data frame
PressWalkDat$Config <- factor(PressWalkDat$Config, allConfigs)

UnLandDat <- as_tibble(UnLandDat) # creating the data frame
UnLandDat$Config <- factor(UnLandDat$Config, allConfigs)

IMUdat_Trail <- as_tibble(IMUdat_Trail) # creating the data frame
IMUdat_Trail$Config <- factor(IMUdat_Trail$Config, allConfigs)

Static <- as_tibble(Static) # creating the data frame
Static$Config <- factor(Static$Config, allConfigs)

treadmill  <- as_tibble(treadmill )
treadmill$Config <- factor(treadmill$Config, allConfigs)


# withinSubPlot <- function(inputDF, colName, dir) {
#   
#   # direction can be 'lower' or higher'. It is the direction of change that is better. 
#   # For example, for contact time lower is better. so we put 'lower'. for jump height, higher is better, so we put higher. 
#   meanDat <- inputDF %>%
#     group_by(Subject, Config) %>%
#     summarize(mean = mean(!! sym(colName),na.rm = TRUE))
#   
#   if (dir == 'lower'){
#     whichConfig <- meanDat %>%
#       group_by(Subject) %>%
#       summarize(
#         BestConfig = Config[which.min(mean)]
#       )
#     
#   } else if (dir == 'higher') {
#     whichConfig <- meanDat %>%
#       group_by(Subject) %>% 
#       summarize(
#         BestConfig = Config[which.max(mean)]
#       )
#     
#   }
#   
#   whichConfig <- merge(meanDat, whichConfig)
#   
#   ggplot(data = whichConfig, mapping = aes(x = as.factor(Config), y = mean, col = BestConfig, group = Subject)) + geom_point(size = 4) + 
#     geom_line() + xlab('Configuration') + scale_color_manual(values=c("#000000","#00966C", "#ECE81A","#DC582A","#CAF0E4")) + theme(text = element_text(size = 16)) + ylab(paste0({{colName}})) 
#   
# }

withinSubPlotAvg <- function(inputDF, colName, dir = 'lower', yLabel = NULL) {
  # Validate the `dir` input
  if(!dir %in% c('lower', 'higher')){
    stop("The 'dir' argument must be either 'lower' or 'higher'.")
  }
  # Calculate the mean for each Subject and Config, removing NA values
  meanDat <- inputDF %>%
    group_by(Subject, Config) %>%
    summarize(mean = mean(!! sym(colName), na.rm = TRUE), .groups = 'drop')
  # Determine the best configuration based on the direction
  if (dir == 'lower'){
    whichConfig <- meanDat %>%
      group_by(Subject) %>%
      reframe(BestConfig = Config[which.min(mean)])
  } else if (dir == 'higher') {
    whichConfig <- meanDat %>%
      group_by(Subject) %>%
      reframe(BestConfig = Config[which.max(mean)])
  }
  # Rename BestConfig to Config for merging
  whichConfig <- whichConfig %>%
    rename(Config = BestConfig)
  # Merge the best configuration back to the mean data
  mergedData <- merge(meanDat, whichConfig, by = c("Subject", "Config"))
  # Calculate overall mean for each Config, removing NA values
  overallMean <- meanDat %>%
    group_by(Config) %>%
    summarize(overallMean = mean(mean, na.rm = TRUE), .groups = 'drop')
  # Plotting with ggplot2
  plot <- ggplot() +
    geom_point(data = meanDat, mapping = aes(x = as.factor(Config), y = mean, group = Subject, color = 'Subject Means'), size = 3, alpha = 0.5) +
    geom_line(data = meanDat, mapping = aes(x = as.factor(Config), y = mean, group = Subject, color = 'Subject Means'), alpha = 0.5) +
    geom_point(data = overallMean, mapping = aes(x = as.factor(Config), y = overallMean, color = 'Overall Mean'), size = 4, shape = 17) +
    geom_line(data = overallMean, mapping = aes(x = as.factor(Config), y = overallMean, group = 1, color = 'Overall Mean'), linewidth = 1.5) +
    scale_color_manual(values = c('Subject Means' = 'grey', 'Overall Mean' = '#003C4C')) +
    xlab('Configuration') +
    theme(text = element_text(size = 16), legend.title = element_blank())
  # Set y-axis label
  if (!is.null(yLabel)) {
    plot <- plot + ylab(yLabel)
  } else {
    plot <- plot + ylab(paste0(colName))
  }
  print(plot)
}


extractVals <- function(dat, mod, configNames, baseConfig, var, dir) {
  
  Config = rep(NA, length(configNames))
  ProbImp = matrix(0, length(configNames))
  lowCI = matrix(0, length(configNames))
  highCI = matrix(0, length(configNames))
  
  for (i in 1:length(configNames)) {
    # This function takes the original dataframe (dat, same one entered into runmod), the Bayesian model from brms (runmod), 
    # the configuration Name, and the variable you are testing. It returns:
    # [1] the probabality the variable was better in the test config vs. the baseline config
    # [3] the lower bound of the bayesian 95% posterior interval (as percent change from baseline) 
    # [4] the upper bound of the bayesian 95% posterior interval (as percent change from baseline)
    #i = 1
    
    configName = configNames[i]
    configColName <- paste('b_Config', configName, sep = "")
    posterior <- posterior_samples(mod)
    
    if (dir == 'lower'){
      prob <- sum(posterior[,configColName] < 0) / length(posterior[,configColName])
      
    } else if (dir == 'higher') {
      
      prob <- sum(posterior[,configColName] > 0) / length(posterior[,configColName])
    }
    
    ci <- posterior_interval(mod, prob = 0.80)
    ciLow <- ci[configColName,1] 
    ciHigh <- ci[configColName,2]
    
    SDdat <- dat %>%
      group_by(Subject) %>%
      summarize(sd = sd(!! sym(var), na.rm = TRUE), mean = mean(!! sym(var), na.rm = TRUE))
    
    meanSD = mean(SDdat$sd , na.rm = TRUE)
    mean = mean(SDdat$mean, na.rm = TRUE)
    ci_LowPct <- meanSD*ciLow/mean*100
    ci_HighPct <- meanSD*ciHigh/mean*100
    
    output = list('Config:', configName, 'Probability of Improvement:', prob, 'Worse end of CI:', ci_LowPct, 'Best end of CI:', ci_HighPct)
    Config[i] = configName
    ProbImp[i] = prob
    lowCI[i] = ci_LowPct
    highCI[i] = ci_HighPct
  }
  ProbImp = round(ProbImp*100)
  lowCI = round(lowCI, 1)
  highCI = round(highCI,1)
  output = cbind(Config, ProbImp, lowCI, highCI)
  
  colnames(output) = c('Config', 'Probability of Improvement', 'Low end of CI', 'High end of CI')
  
  sentences = rep(NA, nrow(output))
  
  for (i in 1:nrow(output)){
    if (as.numeric(output[i,2]) >= 90){
      sentences[i] <- paste0('We have meaningful confidence that ',output[i,1], ' outperformed ', baseConfig, ' (',output[i,2], '%)', '\n', '\t', '- Estimated difference: ',output[i,3],' to ',output[i,4],'%' )
    } else if (as.numeric(output[i,2]) >= 80) {      
      sentences[i] <- paste('We have moderate confidence that',output[i,1], 'outperformed', baseConfig, '(',output[i,2], '%)','\n', '\t', '- Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 70){
      sentences[i] <- paste('We have minimal confidence that',output[i,1], 'outperformed', baseConfig, '(',output[i,2], '%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 30){
      sentences[i] <- paste('There were inconsistent differences between',output[i,1],'and',baseConfig,'(',output[i,2],'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 20){
      sentences[i] <- paste('We have minimal confidence that',output[i,1],'performed worse than',baseConfig,'(',(100 - as.numeric(output[i,2])),'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else if (as.numeric(output[i,2]) >= 10){
      sentences[i] <- paste('We have moderate confidence that',output[i,1],'performed worse than',baseConfig,'(',(100 - as.numeric(output[i,2])),'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    } else {
      sentences[i] <- paste('We have meaningful confidence that',output[i,1],'performed worse than',baseConfig,'(',(100 - as.numeric(output[i,2])),'%)','\n', '\t', 'Estimated difference:',output[i,3],'to',output[i,4],'%')
    }
  }
  
  writeLines(sentences)
  return()
}

# Setting up  "Best Of" line plots 
withinSubQualPlot <- function(inputDF) {
  
  # direction can be 'lower' or higher'. It is the direction of change that is better. 
  # For example, for contact time lower is better. so we put 'lower'. for jump height, higher is better, so we put higher. 
  
  whichConfig <- inputDF %>%
    group_by(Subject) %>%
    summarize(
      BestConfig = Config[which.max(OverallFit)]
    )
  
  whichConfig <- merge(inputDF, whichConfig)
  
  ggplot(data = whichConfig, mapping = aes(x = as.factor(Config), y = OverallFit, col = BestConfig, group = Subject)) + geom_point(size = 4) + 
    geom_line() + xlab('Configuration') + scale_color_manual(values=c("#000000", "#00966C", "#ECE81A","#DC582A","#CAF0E4")) + ylab('Rating') + theme(text = element_text(size = 16))
  
}



# qual average plot
withinSubQualAvg <- function(inputDF) {
  
  # direction can be 'lower' or higher'. It is the direction of change that is better. 
  # For example, for contact time lower is better. so we put 'lower'. for jump height, higher is better, so we put higher. 
  # Calculate the mean for each Subject and Config, removing NA values
  meanDat <- inputDF %>%
    group_by(Subject, Config) %>%
    summarize(mean = mean(OverallFit, na.rm = TRUE), .groups = 'drop')
  
  
  whichConfig <- inputDF %>%
    group_by(Subject) %>%
    summarize(
      BestConfig = Config[which.max(OverallFit)]
    )
  
  whichConfig <- whichConfig %>%
    rename(Config = BestConfig)
  
  mergeDat <- merge(meanDat, whichConfig)
  
  overallMean <- meanDat %>%
    group_by(Config) %>%
    summarize(overallMean = mean(mean, na.rm = TRUE), .groups = 'drop')
  # Plotting with ggplot2
  plot <- ggplot() +
    geom_point(data = meanDat, mapping = aes(x = as.factor(Config), y = mean, group = Subject, color = 'Subject Means'), size = 3, alpha = 0.5) +
    geom_line(data = meanDat, mapping = aes(x = as.factor(Config), y = mean, group = Subject, color = 'Subject Means'), alpha = 0.5) +
    geom_point(data = overallMean, mapping = aes(x = as.factor(Config), y = overallMean, color = 'Overall Mean'), size = 4, shape = 17) +
    geom_line(data = overallMean, mapping = aes(x = as.factor(Config), y = overallMean, group = 1, color = 'Overall Mean'), linewidth = 1.5) +
    scale_color_manual(values = c('Subject Means' = 'grey', 'Overall Mean' = '#003C4C')) +
    xlab('Configuration') + ylab('Rating') +
    theme(text = element_text(size = 16), legend.title = element_blank()) 
    
  
  print(plot)
  
}

###############################
```

# **Qualitative ( CF: , IF: )**

```{r}
#| echo: false
#| layout-ncol: 2
#| tbl-column: page-right
#| fig-column: page-left
#| warning: false
#| fig-height: 7
#| fig-width: 4


qualDat %>%
  pivot_longer(cols = OverallFit:Cuff, 
               names_to = "Location", values_to = "Rating") %>%
  group_by(Location, Config) %>%
  summarize(
    Avg = median(Rating, na.rm = TRUE) # median avg
  ) %>%
  gt()


#Defining the rating for the location 
#Density plots for fit ratings of shoe locations
qualDat <- pivot_longer(qualDat, cols = Forefoot:Cuff, names_to = 'Location', values_to = 'Rating')

FF <- qualDat %>% 
  filter(Location=="Forefoot")


qualDat$Location <- factor(qualDat$Location, c('Forefoot', 'Midfoot', 'Heel', 'Cuff')) 

```

```{r}
#| echo: false

withinSubQualPlot(qualDat)
ggplot(qualDat, mapping = aes(x = Rating, fill = Config)) + 
  geom_histogram(position = 'dodge', binwidth = 1) + facet_wrap(~Location) + scale_fill_manual(values=c("#999999", "#00966C", "#ECE81A","#DC582A","#CAF0E4")) +
  ylab('Responses') + theme(text=element_text(size=20)) + geom_vline(xintercept = 5, linewidth = 1)
```

```{r}
#| echo: false

#| # average qual within plot

withinSubQualAvg(qualDat)
```

**Dial Torque**

```{r}
#| echo: false
#| warning: false


qualDat %>%
  group_by(Config)%>%
  summarize(
    R_Torque_Cuff = mean(R_DialTorque1, na.rm = TRUE),
    # R_Torque_Instep = mean(R_DialTorque1, na.rm = TRUE),
    L_Torque_Cuff = mean(L_DialTorque1, na.rm = TRUE),
    # L_Torque_Instep = mean(L_DialTorque1, na.rm = TRUE)
  )%>%
  gt()


ggplot(qualDat, aes(x=Config, y = R_DialTorque1, color = Config, group= Subject)) + 
  geom_point(size = 4)+ 
  geom_line(aes(color=Config))+
  # facet_wrap(~Subject)+
  scale_color_manual(values=c("#000000","#00966C", "#ECE81A","#DC582A","#CAF0E4"))+ 
  theme(text = element_text(size = 16))+ 
  ylab('Instep Dial - Torque [N-cm]')+ 
  xlab('Config')+
  ggtitle('Right Foot')



withinSubPlotAvg(qualDat, colName ='R_DialTorque1', dir = 'higher')  + ylab('Instep Dial - Torque [N-cm]')


torqueDat <- qualDat %>%
  group_by(Subject) %>%
  mutate(z_score = scale(R_DialTorque1)) %>%
  group_by(Config)


torqueMod <- brm(data = torqueDat, # Bayes model
              family = gaussian,
              z_score ~  Config + (1  | Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


extractVals(torqueDat , torqueMod, otherConfigs, baseline, 'R_DialTorque1', 'higher')

```

# Efficiency

### Positive Center of Mass Work- Uphill walking (lower is better)

```{r}
#| echo: false
#| warning: false
#| include: false

treadmill_UH <- subset(treadmill , treadmill$Slope == '10')
# Level
#organizing data - grouping by subject and config by the variable being observed
psCOM_UH <- treadmill_UH %>% 
  group_by(Subject) %>%
  filter(COMWork_pos > 30) %>%
  mutate(z_score = scale(COMWork_pos))%>%
  group_by(Config) 



#Normalization histograms, Check for normalish distribution/outliers
ggplot(data = psCOM_UH, aes(x = COMWork_pos, fill = Config)) + geom_histogram() + facet_wrap(~Subject) 


## Bayes model 
# This model takes a while to run and may  crash your session 
#Wait until you receive a warning about rtools to run anything else
psCOM_UH_mod <- brm(data = psCOM_UH, 
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


```

```{r}
#| echo: false
#| warning: false
#| layout-ncol: 2 


p <- withinSubPlotAvg(psCOM_UH, colName = 'COMWork_pos', dir = 'lower')
p + ylab('Postitive COM - Uphill (J)')


extractVals(psCOM_UH, psCOM_UH_mod, otherConfigs, baseline, 'COMWork_pos', 'lower')
```

### Negative Center of Mass - Downhill (Higher is better)

```{r}
#| echo: false
#| warning: false
#| include: false



treadmill_DH <- subset(treadmill, treadmill$Slope == '-10')
# Level
#organizing data - grouping by subject and config by the variable being observed
ngCOM_DH <- treadmill_DH  %>% 
  group_by(Subject) %>%
  # filter(COMWork_pos > 30) %>%
  mutate(z_score = scale(COMWork_neg))%>%
  group_by(Config) 



#Normalization histograms, Check for normalish distribution/outliers
ggplot(data = ngCOM_DH, aes(x = COMWork_neg, fill = Config)) + geom_histogram() + facet_wrap(~Subject) 


## Bayes model 
# This model takes a while to run and may  crash your session 
#Wait until you receive a warning about rtools to run anything else
ngCOM_DH_mod <- brm(data = ngCOM_DH , 
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)
```

```{r}
#| echo: false
#| warning: false
#| layout-ncol: 2 

p <- withinSubPlotAvg(ngCOM_DH, colName = 'COMWork_neg', dir = 'higher')
p + ylab('Negative COM - Downhill (J)')


extractVals(ngCOM_DH, ngCOM_DH_mod, otherConfigs, baseline, 'COMWork_neg', 'higher')
```

### **Walking Speed (higher is better)** **- Uneven Terrain Walking**

```{r}
#| echo: false
#| warning: false
#| include: false


################

###### Walking Speed

Speeddat <- IMUdat_Trail %>% 
  group_by(Subject) %>%
  filter(imuSpeed > 0.25) %>%
  mutate(z_score = scale(imuSpeed)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
ggplot(data = Speeddat, aes(x = imuSpeed, fill = Config)) + geom_histogram() + facet_wrap(~Subject)

Speeddat <- subset(Speeddat, Speeddat$z_score < 2) #removing outliers
Speeddat <- subset(Speeddat, Speeddat$z_score > -2)

ggplot(data = Speeddat, aes(x = imuSpeed, fill = Config)) + geom_histogram() + facet_wrap(~Subject)




# Note for trail run metrics: Warmup was reduced (from 1000 to 400)
SpeeddatMod <- brm(data = Speeddat, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 400, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


```

```{r}
#| echo: false
#| warning: false
#| layout-ncol: 2  


p <- withinSubPlotAvg(Speeddat, colName = 'imuSpeed', dir = 'higher')
p + ylab('Walking Speed (m/s)')


extractVals(Speeddat, SpeeddatMod, otherConfigs, baseline, 'imuSpeed', 'higher') 
```

### **Toe Clawing: Peak Toe Pressure (Lower is Better) - Single Leg Landing and Uneven Terrain Walking**

```{r}
#| echo: false
#| warning: false
#| include: false


################

###### Peak Toe Pressure Walking

PeakToeWalkdat <- PressWalkDat %>% 
  group_by(Subject) %>%
  mutate(z_score = scale(maxmaxToes)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
ggplot(data = PeakToeWalkdat, aes(x = maxmaxToes, fill = Config)) + geom_histogram() + facet_wrap(~Subject)

p <- withinSubPlot(PeakToeWalkdat, colName = 'maxmaxToes', dir = 'lower')
p + ylab('Peak Toe Pressure (kPa)')

# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
PeakToeWalkdatMod <- brm(data = PeakToeWalkdat, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

```

```{r}
#| echo: false
#| warning: false
#| layout-ncol: 2 

p <- withinSubPlotAvg(PeakToeWalkdat, colName = 'maxmaxToes', dir = 'lower')
p + ylab('Peak Toe Pressure (kPa)')

extractVals(PeakToeWalkdat, PeakToeWalkdatMod, otherConfigs, baseline, 'maxmaxToes', 'lower')
```

# Stability

### **Ankle Stability: Peak Eversion Velocity (lower is better) - Uneven Terrain Walking**

```{r}
#| echo: false
#| warning: false
#| include: false 


###### Peak eversion velocity

Everdat <- IMUdat_Trail %>% 
  group_by(Subject) %>%
  filter(pIEgyro > 0) %>%
  mutate(z_score = scale(pIEgyro)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
ggplot(data = Everdat, aes(x = pIEgyro, fill = Config)) + geom_histogram() + facet_wrap(~Subject) 


Everdat <- subset(Everdat, Everdat$z_score < 2) #removing outliers
Everdat <- subset(Everdat, Everdat$z_score > -2)




EverdatMod <- brm(data = Everdat, # Bayes model
              family = gaussian,
              z_score ~ Config + imuSpeed + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 100, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


```

```{r}
#| echo: false
#| warning: false
#| layout-ncol: 2  



p <- withinSubPlot(Everdat, colName = 'pIEgyro', dir = 'lower')
p + ylab('Eversion Velocity (deg/s)')

extractVals(Everdat, EverdatMod, otherConfigs, baseline, 'pIEgyro', 'lower')

```

### **Knee Joint Loading: Knee Abduction Moment (lower magnitude is better)**

```{r}
#| echo: false
#| warning: false
#| include: false 


################

### SLL Knee Abduction Moment


OGLandDat$RkneeABDMom<- as.numeric(OGLandDat$RkneeABDMom)


KABDOGLandDat <- OGLandDat %>% 
  group_by(Subject)%>%
  filter(RkneeABDMom > -500) %>%
  mutate(z_score = scale(RkneeABDMom))%>% 
  group_by(Config)





# Look at histogram of the data if any outliers need to be removed
ggplot(data = KABDOGLandDat, aes(x = RkneeABDMom, fill = Config)) + geom_histogram() + facet_wrap(~Subject)

KABDOGLandDat <- subset(KABDOGLandDat, KABDOGLandDat$z_score < 2) #remov. outliers
KABDOGLandDat <- subset(KABDOGLandDat, KABDOGLandDat$z_score > -2)




KABDOGLandDatMod <- brm(data = KABDOGLandDat, 
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)



```

```{r}
#| echo: false
#| warning: false
#| layout-ncol: 2  

p <- withinSubPlot(KABDOGLandDat, colName = 'RkneeABDMom', dir = 'higher')
p + ylab('Knee Abduction Moment (Nm)')



extractVals(KABDOGLandDat, KABDOGLandDatMod, otherConfigs, baseline, 'RkneeABDMom', 'higher')
```

### **Stability (faster is better) - Landing on Uneven Terrain**

```{r}
#| echo: false
#| warning: false
#| include: false 


TimeUnLandDat <- UnLandDat %>% 
  group_by(Subject) %>%
  mutate(z_score = scale(StabalizeTime)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
ggplot(data = TimeUnLandDat, aes(x = StabalizeTime, fill = Config)) + geom_histogram() + facet_wrap(~Subject)

TimeUnLandDat <- subset(TimeUnLandDat, TimeUnLandDat$z_score < 2) #remov. outliers
TimeUnLandDat <- subset(TimeUnLandDat, TimeUnLandDat$z_score > -2)



TimeUnLandDatMod <- brm(data = TimeUnLandDat, 
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)


```

```{r}
#| echo: false
#| warning: false
#| layout-ncol: 2   


p <- withinSubPlot(TimeUnLandDat, colName = 'StabalizeTime', dir = 'lower')
p + ylab('Stabilization Time (s)') 

extractVals(TimeUnLandDat, TimeUnLandDatMod, otherConfigs, baseline, 'StabalizeTime', 'lower')
```

# Quantitative Fit

### **Heel Hold: Heel contact area (higher is better) - Uneven Terrain Walking**

```{r}
#| echo: false
#| warning: false
#| include: false 

newSub <- gsub(" ", "", qualDat$Subject)

rdial <- qualDat %>%
  select(Subject, Config, R_DialTorque1, R_DialTorque2)%>%
  mutate(Subject = newSub)

Press <- left_join(PressWalkDat, rdial, by = c('Subject', 'Config'), relationship = 'many-to-many')


Press <- as_tibble(Press) # creating the data frame
Press$Config <- factor(Press$Config, allConfigs)
###### Heel Contact

HeelCondat <- PressWalkDat %>% 
  group_by(Subject) %>%
  mutate(z_score = scale(heelAreaP)) %>% 
  group_by(Config)

# Look at histogram of the data if any outliers need to be removed
ggplot(data = HeelCondat, aes(x = heelAreaP, fill = Config)) + geom_histogram() + facet_wrap(~Subject)

HeelCondat <- subset(HeelCondat, HeelCondat$z_score < 2) #remov. outliers
HeelCondat <- subset(HeelCondat, HeelCondat$z_score > -2)





# Note for trail run metrics: Warmup was reduced (from 1000 to 500)
HeelCondatMod <- brm(data = HeelCondat, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

```

```{r}
#| echo: false
#| warning: false
#| layout-ncol: 2  


p <- withinSubPlot(HeelCondat, colName = 'heelAreaP', dir = 'higher')
p + ylab('Heel Contact (%)') 

extractVals(HeelCondat, HeelCondatMod, otherConfigs, baseline, 'heelAreaP', 'higher')
```

### **Static Pressure - Max Dorsal Pressure**

```{r}
#| echo: false
#| warning: false
#| include: false 


################
###### peak dorsal pressure 

Static <- subset(Static, Static$Movement == 'Standing')


peakDorsal <- Static%>% 
  group_by(Subject) %>%
  mutate(z_score = scale(maxDorsalPressure)) %>% 
  group_by(Config)

ggplot(data = peakDorsal, aes(x = maxDorsalPressure, fill = Config)) + geom_histogram() + facet_wrap(~Subject)

# peakDorsal  <- subset(peakDorsal , peakDorsal $z_score < 2) #remov. outliers
# peakDorsal  <- subset(peakDorsal , peakDorsal $z_score > -2)
# 




DorsalMaxMod <- brm(data = peakDorsal, # Bayes model
              family = gaussian,
              z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained 
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)

```

```{r}
#| echo: false
#| warning: false
#| layout-ncol: 2  


p <- withinSubPlot(peakDorsal, colName = 'maxDorsalPressure', dir = 'lower')
p + ylab('Max Dorsal Pressure (kPa)') 



extractVals(peakDorsal, DorsalMaxMod, otherConfigs, baseline, 'maxDorsalPressure', 'lower')

```

### **Static Pressure - Mean Dorsal Pressure**

```{r}
#| echo: false
#| warning: false
#| include: false 


################
###### peak dorsal pressure 

Static <- subset(Static, Static$Movement == 'Standing')


avgDorsal <- Static%>% 
  group_by(Subject) %>%
  mutate(z_score = scale(meanDorsalPressure)) %>% 
  group_by(Config)

ggplot(data = avgDorsal, aes(x = meanDorsalPressure, fill = Config)) + geom_histogram() + facet_wrap(~Subject)

# peakDorsal  <- subset(peakDorsal , peakDorsal $z_score < 2) #remov. outliers
# peakDorsal  <- subset(peakDorsal , peakDorsal $z_score > -2)
# 




DorsalMeanMod <- brm(data = avgDorsal, # Bayes model
              family = gaussian,
              # z_score ~ Config + (1 + Config| Subject), #fixed effect of configuration and time period with a different intercept and slope for each subject
              z_score ~ Config + (1|Subject),
              prior = c(prior(normal(0, 1), class = Intercept), #The intercept prior is set as a mean of 25 with an SD of 5 This may be interpreted as the average loading rate (but average is again modified by the subject-specific betas)
                        prior(normal(0, 1), class = b), #beta for the intercept for the change in loading rate for each configuration
                        prior(cauchy(0, 1), class = sd), #This is a regularizing prior, meaning we will allow the SD of the betas to vary across subjects
                        prior(cauchy(0, 1), class = sigma)), #overall variability that is left unexplained
              iter = 2000, warmup = 1000, chains = 4, cores = 4,
              control = list(adapt_delta = .975, max_treedepth = 20),
              seed = 190831)
```

```{r}
#| echo: false
#| warning: false
#| layout-ncol: 2  


p <- withinSubPlotAvg(avgDorsal, colName = 'meanDorsalPressure', dir = 'higher')
p + ylab('Mean Dorsal Pressure (kPa)') 

extractVals(avgDorsal, DorsalMeanMod, otherConfigs, baseline, 'meanDorsalPressure', 'higher')

```

**Radar Plots**

```{r}
#| echo: false
#| warning: false
#| include: false 

### radar for MED config

Efficiency <- 66 

Stability <- 33

Fit <- 76

Qual <- 77

data <- t(c(Efficiency, Stability, Fit, Qual))

data <- as.data.frame(data)
improvThresh<- as.data.frame(t(c(70,70,70,70)))
equalThresh<- as.data.frame(t(c(50,50,50,70)))

min =as.data.frame(t(rep(0, 4)))
max = as.data.frame(t(rep(100,4)))
data <- rbind(max, min, improvThresh, equalThresh, data)

colnames(data) <- c("Efficiency", "Stability", "Fit", "Qual")
data$Qual[4] <- 92 # qual for baseline

colors <- c("#C8C9C7","#53565A", "#00966C")

create_beautiful_radarchart <- function(data, color = "#00966C",
                                        vlabels = colnames(data), vlcex = 1.2,
                                        caxislabels = NULL, title = NULL, ...){
  radarchart(
    data, axistype = 1,
    # Customize the polygon
    pcol = color, pfcol = scales::alpha(color, 0.5), plwd = 2, plty = 1,
    # Customize the grid
    cglcol = "grey", cglty = 1, cglwd = 0.8,
    # Customize the axis
    axislabcol = "grey",
    # Variable labels
    vlcex = vlcex, vlabels = vlabels,
    caxislabels = caxislabels, title = title, ...
  )
}


create_beautiful_radarchart(data = data, color = colors)

legend(x = "topright", inset = c(- 0.3, 0.2), legend = c("Threshold for confidence in improvement.", "PFS", "IF"),
       bty = "n", pch = 20, col = colors, text.col = "black", cex = .8, pt.cex = 2)

# legend(x = "topright", inset = c(- 0.3, 0.2), legend = c("Threshold for confidence in improvement", "CI",), bty = "n", pch = 20, col = colors, text.col = "black", cex = 1, pt.cex = 1)
# ## This code gives a visual representation of how a shoe performed against a baseline shoe in the form of a radar plot
# #This happens by assigning different averaged ratings to different segments
# #You are only adding the shoe being tested to the ratings, the baseline shoe is always set to 50 for a clear comparison
# #The shoe being tested is rated by the average percentile confidence in each segment

# ###For example, if a PFS shoe had 75% confidence in CMJ  and 50% in skater for contact time, the average rating for agility would be 62.5 -> 63


# # #### LAT Config

Efficiency <- 47

Stability <- 52

Fit <- 52

Qual <- 91

data <- t(c(Efficiency, Stability, Fit, Qual))

data <- as.data.frame(data)

improvThresh<- as.data.frame(t(c(70,70,70,70)))
equalThresh<- as.data.frame(t(c(50,50,50,94)))

min =as.data.frame(t(rep(0, 4)))
max = as.data.frame(t(rep(100,4)))
data <- rbind(max, min, improvThresh, equalThresh, data)

colnames(data) <- c("Efficiency", "Stability", "Fit", "Qual")

data$Qual[4] <- 92 # qual for baseline


colors <- c("#C8C9C7","#53565A", "#00966C")

create_beautiful_radarchart <- function(data, color = "#00966C",
                                        vlabels = colnames(data), vlcex = 1.2,
                                        caxislabels = NULL, title = NULL, ...){
  radarchart(
    data, axistype = 1,
    # Customize the polygon
    pcol = color, pfcol = scales::alpha(color, 0.5), plwd = 2, plty = 1,
    # Customize the grid
    cglcol = "grey", cglty = 1, cglwd = 0.8,
    # Customize the axis
    axislabcol = "grey",
    # Variable labels
    vlcex = vlcex, vlabels = vlabels,
    caxislabels = caxislabels, title = title, ...
  )
}


create_beautiful_radarchart(data = data, color = colors)
```
